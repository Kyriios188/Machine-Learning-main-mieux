{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives of the practical work\n",
    "\n",
    "The objective is to get hands on experience on the fundamental elements of neural networks:\n",
    " \n",
    " - perceptron architecture (linear regression)\n",
    " - loss function\n",
    " - empirical loss\n",
    " - gradient descent\n",
    "\n",
    "For this we will implement from scratch the data-structure and algorithms to train a perceptron. Note that slides related to the perceptron and neural networks in general are available on [moodle](https://moodle.insa-toulouse.fr/course/view.php?id=1822#section-2).\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The objective of the regression is the prediction of the hydrodynamic performance of sailing yachts from dimensions and velocity.\n",
    "The **inputs** are linked to dimension and hydrodynamics characteristics:\n",
    "1. Longitudinal position of the center of buoyancy\n",
    "(*flottabilité*), adimensional.\n",
    "2. Prismatic coefficient, adimensional.\n",
    "3. Length-displacement ratio, adimensional.\n",
    "4. Beam -draught ratio ((*tiran d’eau*), adimensional.\n",
    "5. Length-beam ratio, adimensional.\n",
    "6. Froude number, adimensional\n",
    "\n",
    "**Target value/predicted value (Output)** = Residuary resistance per unit weight of\n",
    "displacement, adimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some useful libraries and functions\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "def print_stats(dataset):\n",
    "    \"\"\"Print statistics of a dataset\"\"\"\n",
    "    print(pandas.DataFrame(dataset).describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset available\n"
     ]
    }
   ],
   "source": [
    "# Download the data set and place in the current folder (works on linux only)\n",
    "filename = 'yacht_hydrodynamics.data'\n",
    "\n",
    "import os.path\n",
    "import requests\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    print(\"Downloading dataset...\")\n",
    "    r = requests.get('https://arbimo.github.io/tp-supervised-learning/tp2/' + filename)\n",
    "    open(filename , 'wb').write(r.content)\n",
    "    \n",
    "print('Dataset available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the dataset\n",
    "\n",
    "- how many examples are there in the dataset?\n",
    "- how many features for each example?\n",
    "- what is the ground truth of the 10th example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "des exemples y en a: 308\n",
      "                0           1           2           3           4           5\n",
      "count  308.000000  308.000000  308.000000  308.000000  308.000000  308.000000\n",
      "mean    -2.381818    0.564136    4.788636    3.936818    3.206818    0.287500\n",
      "std      1.513219    0.023290    0.253057    0.548193    0.247998    0.100942\n",
      "min     -5.000000    0.530000    4.340000    2.810000    2.730000    0.125000\n",
      "25%     -2.400000    0.546000    4.770000    3.750000    3.150000    0.200000\n",
      "50%     -2.300000    0.565000    4.780000    3.955000    3.150000    0.287500\n",
      "75%     -2.300000    0.574000    5.100000    4.170000    3.510000    0.375000\n",
      "max      0.000000    0.600000    5.140000    5.350000    3.640000    0.450000\n",
      "f([-5.    0.6   4.78  4.24  3.15  0.35]) = 8.62\n",
      "f([-5.     0.565  4.77   3.99   3.15   0.15 ]) = 0.18\n",
      "f([-2.3    0.565  4.78   5.35   2.76   0.15 ]) = 0.29\n",
      "f([-5.     0.6    4.78   4.24   3.15   0.325]) = 6.2\n",
      "f([0.    0.53  4.78  3.75  3.15  0.175]) = 0.59\n",
      "f([-2.3    0.568  4.78   3.99   3.17   0.25 ]) = 1.82\n",
      "f([-5.    0.53  4.78  3.75  3.15  0.45]) = 55.87\n",
      "f([-5.     0.565  5.1    3.94   3.51   0.175]) = 0.45\n",
      "f([-2.2    0.546  4.78   4.13   3.07   0.3  ]) = 3.45\n",
      "f([-5.     0.565  4.77   3.99   3.15   0.25 ]) = 1.83\n",
      "Le ground truth du dixième c'est 1.83\n"
     ]
    }
   ],
   "source": [
    "# loads the dataset and slip between inputs (X) and ground truth (Y)\n",
    "dataset = np.genfromtxt(\"yacht_hydrodynamics.data\", delimiter='')\n",
    "X = dataset[:, :-1] # examples features\n",
    "Y = dataset[:, -1]  # ground truth\n",
    "print(\"des exemples y en a: \"+str(len(X))) #y a donc 308 exemples\n",
    "# Print the first 5 examples\n",
    "print_stats(X)\n",
    "for i in range(0,10):\n",
    "    print(f\"f({X[i]}) = {Y[i]}\")\n",
    "    if (i==9):\n",
    "        print(f\"Le ground truth du dixième c'est {Y[i]}\")\n",
    "        \n",
    "#des features y en a 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command adds a column to the inputs.\n",
    "\n",
    "- what is in the value added this column?\n",
    "- why are we doing this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On insère une colonne de 1 au début\n",
    "Cela correspond à la constante w0 nécessaire pour la suite. C'est la valeur d'initialisation, elle sera modifiée ensuite au fil de l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0           1           2           3           4           5  \\\n",
      "count  308.0  308.000000  308.000000  308.000000  308.000000  308.000000   \n",
      "mean     1.0   -2.381818    0.564136    4.788636    3.936818    3.206818   \n",
      "std      0.0    1.513219    0.023290    0.253057    0.548193    0.247998   \n",
      "min      1.0   -5.000000    0.530000    4.340000    2.810000    2.730000   \n",
      "25%      1.0   -2.400000    0.546000    4.770000    3.750000    3.150000   \n",
      "50%      1.0   -2.300000    0.565000    4.780000    3.955000    3.150000   \n",
      "75%      1.0   -2.300000    0.574000    5.100000    4.170000    3.510000   \n",
      "max      1.0    0.000000    0.600000    5.140000    5.350000    3.640000   \n",
      "\n",
      "                6  \n",
      "count  308.000000  \n",
      "mean     0.287500  \n",
      "std      0.100942  \n",
      "min      0.125000  \n",
      "25%      0.200000  \n",
      "50%      0.287500  \n",
      "75%      0.375000  \n",
      "max      0.450000  \n"
     ]
    }
   ],
   "source": [
    "X = np.insert(X, 0, np.ones((len(X))), axis= 1)\n",
    "print_stats(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the perceptron\n",
    "\n",
    "![Perceptron for regression](https://arbimo.github.io/tp-supervised-learning/tp2/perceptron-regression.png)\n",
    "\n",
    "We now want to define a perceptron, that is, a function of the form: \n",
    "\n",
    "$h_w(x) = w_0 + w_1 \\times x_1 + \\dots + w_n \\times x_n$\n",
    "\n",
    "- Complete the code snippet below to:\n",
    "  - create the vector of weight `w`\n",
    "  - implement the `h` function that evaluate an example based on the vector of weights\n",
    "  - check if this works on a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros(7)\n",
    "\n",
    "def h(w, x):\n",
    "    s = 0\n",
    "    for i in range(len(x)):\n",
    "        s += x[i] * w[i]\n",
    "    return s\n",
    "\n",
    "print(h(np.array([0, 1, 7]), np.array([1, 2, 3])))\n",
    "print(h(w, X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "Complete the definiton of the loss function below such that, for a **single** example `x` with ground truth `y`, it returns the $L_2$ loss of $h_w$ on `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(w, x, y):\n",
    "    \n",
    "    return (h(w, x) - y)**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical loss\n",
    "\n",
    "Complete the function below to compute the empirical loss of $h_w$ on a **set** of examples $X$ with associated ground truths $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339.2467464285712\n"
     ]
    }
   ],
   "source": [
    "def emp_loss(w, X, Y):\n",
    "    \n",
    "    s = 0\n",
    "    for i in range(len(X)):\n",
    "        s += loss(w, X[i], Y[i])\n",
    "    \n",
    "    return s/len(X)\n",
    "    \n",
    "print(emp_loss(w, X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient update\n",
    "\n",
    "A gradient update is of the form: $w \\gets w + dw$\n",
    "\n",
    "- Complete the function below so that it computes the $dw$ term (the 'update') based on a set of examples `(X, Y)` the step (`alpha`)\n",
    "\n",
    "If you are not sure about the gradient computation, check out the [perceptron slides](https://moodle.insa-toulouse.fr/pluginfile.php/120391/mod_resource/content/1/cm1.pdf) on [Moodle](https://moodle.insa-toulouse.fr/course/view.php?id=1822) (in particular, slide 26). Make sure this computation is clear to you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.000279274, 9.822360000000058e-05, -0.00016181183899999994, -0.0013891775699999998, -0.0012256563099999995, -0.0009122661100000004, 0.00029717197500000005]\n"
     ]
    }
   ],
   "source": [
    "# w : vecteur des poids\n",
    "# dw : vecteur des 'update' de chaque poids\n",
    "\n",
    "def compute_update(w, X, Y, alpha):\n",
    "    \n",
    "    \n",
    "    sum_list = []\n",
    "    \n",
    "    for i in range(len(w)):\n",
    "        s = 0\n",
    "        \n",
    "        for j in range(len(X)):\n",
    "            s +=  (Y[j] - h(w, X[j])) * X[j][i]\n",
    "            \n",
    "        sum_list.append(s)\n",
    "    \n",
    "    return [alpha * e for e in sum_list]\n",
    "\n",
    "print(compute_update(w, X, Y, alpha = 10e-7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "Now implement the gradient descent algorithm that will:\n",
    "\n",
    "- repeatedly apply an update the weights \n",
    "- stops when a max number of iterations is reached (do not consider early stopping for now)\n",
    "- returns the final vector of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descent(w_init, X, Y, alpha, max_iter):\n",
    "    \n",
    "    current_iter = 0\n",
    "    list_w = w_init[:] # deep copy to not alter w_init\n",
    "    \n",
    "    while current_iter < max_iter:\n",
    "        \n",
    "        \n",
    "        for j, w in enumerate(list_w):\n",
    "            w += compute_update(list_w, X, Y, alpha)[j]\n",
    "        \n",
    "        #print(emp_loss(current_w, X, Y))\n",
    "        \n",
    "        current_iter += 1\n",
    "    \n",
    "    return list_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploitation\n",
    "\n",
    "You gradient descent is now complete and you can exploit it to train your perceptron.\n",
    "\n",
    "- Train your perceptron to get a model.\n",
    "- Visualize the evolution of the loss on the training set. Has it converged?\n",
    "- Try training for several choices of `alpha` and `max_iter`. What seem like a reasonable choice?\n",
    "- What is the loss associated with the final model?\n",
    "- Is the final model the optimal one for a perceptron?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#w = np.empty_like(X)\n",
    "# The lower alpha is, the higher max_iter has to be\n",
    "w = np.zeros(7)\n",
    "les_y = []\n",
    "N_TESTS = 1000\n",
    "for i in range(N_TESTS):\n",
    "    \n",
    "    for j in range(len(w)):\n",
    "        w[j] += compute_update(w, X, Y, 10e-7)[j]\n",
    "            \n",
    "    les_y.append(emp_loss(w, X, Y))\n",
    "\n",
    "# Matplotlib affiche la taille de la figure au lieu de la figure elle-même, cette ligne règle le problème\n",
    "%matplotlib inline\n",
    "\n",
    "les_x = [k for k in range(N_TESTS)]\n",
    "plt.plot(les_x, les_y)\n",
    "plt.ylabel(\"Empirical Loss\")\n",
    "plt.ylabel(\"Iteration number\")\n",
    "plt.title(\"Evolution of the empirical loss\")\n",
    "plt.show()\n",
    "\n",
    "# For 10e-7 : 500 is enough, it converges very quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code sample that can be used to visualize the difference between the ground truth and the prediction\n",
    "\n",
    "num_samples_to_plot = 20\n",
    "plt.plot(Y[0:num_samples_to_plot], 'ro', label='y')\n",
    "yw = [h(w,x) for x in X]\n",
    "plt.plot(yw[0:num_samples_to_plot], 'bx', label='$\\hat{y}$')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Examples\")\n",
    "plt.ylabel(\"f(examples)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
